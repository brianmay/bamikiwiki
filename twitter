#!/usr/bin/python

import ConfigParser
import sys
import tweepy
import datetime
import codecs
import os
import filecmp
import pytz
import gdbm
import urllib

from cgi import escape

config = ConfigParser.ConfigParser()
config.read('config.cfg')

consumer_token = config.get('twitter', 'consumer_token')
consumer_secret = config.get('twitter', 'consumer_secret')
auth = tweepy.OAuthHandler(consumer_token, consumer_secret)

state = ConfigParser.ConfigParser()
state.read('state.cfg')
if not state.has_option('twitter', 'key') or not state.has_option('twitter', 'secret'):
    try:
        redirect_url = auth.get_authorization_url()
    except tweepy.TweepError:
        sys.stderr.write('Error! Failed to get request token.\n')
        sys.exit(1)

    sys.stdout.write("goto %s\n" % redirect_url)

    verifier = raw_input('Verifier:')

    try:
        auth.get_access_token(verifier)
    except tweepy.TweepError:
        sys.stderr.write('Error! Failed to get access token.\n')
        sys.exit(1)

    api = tweepy.API(auth)

    state.add_section("twitter")
    state.set('twitter', 'key', auth.access_token.key)
    state.set('twitter', 'secret', auth.access_token.secret)
    with open('state.cfg', 'wb') as configfile:
        state.write(configfile)
else:
    key = state.get('twitter', 'key')
    secret = state.get('twitter', 'secret')
    auth.set_access_token(key, secret)
    api = tweepy.API(auth)
    key = None
    secret = None

base = config.get('main', 'base')
timezone = pytz.timezone(config.get('main', 'timezone'))
now = pytz.utc.localize(datetime.datetime.utcnow())
now = now.astimezone(timezone)
now = timezone.normalize(now)

all_status = {}

db = gdbm.open("cache.db", "c")

def tofirstdayinisoweek(year, week):
    ret = datetime.datetime.strptime('%04d-%02d-1' % (year, week), '%Y-%W-%w')
    if datetime.date(year, 1, 4).isoweekday() > 4:
        ret -= timedelta(days=7)
    return ret

def expand_entities(entities, text):
    expanded = {}
    end = []

    if 'media' in entities:
        for e in entities['media']:
            a, b = e['indices']
            url = e['expanded_url']
            display = e['display_url']
            expanded[a] = {
                'text': '<a href="%s">%s</a>' % (
                    escape(url, True), escape(display)),
                'b': b
            }
        end.append('<img src="%s" alt="" />' % (
                escape(e['media_url_https'])
            ))
    if 'urls' in entities:
        for e in entities['urls']:
            a, b = e['indices']
            url = e['expanded_url']
            display = e['display_url']
            expanded[a] = {
                'text': '<a href="%s">%s</a>' % (
                    escape(url, True), escape(display)),
                'b': b
            }
    if 'user_mentions' in entities:
        for e in entities['user_mentions']:
            a, b = e['indices']
            user_url = "https://twitter.com/%s" % e['screen_name']
            expanded[a] = {
                'text': '@<a href="%s" title="%s">%s</a>' % (
                    escape(user_url, True),
                    escape(e['name'], True),
                    escape(e['screen_name'])),
                'b': b
            }
    if 'hashtags' in entities:
        for e in entities['hashtags']:
            a, b = e['indices']
            query = { 'q': "#%s"%e['text'] }
            hash_url = "https://twitter.com/search?%s" % urllib.urlencode(query)
            expanded[a] = {
                'text': '#<a href="%s">%s</a>' % (
                    escape(hash_url, True),
                    escape(e['text'])),
                'b': b
            }

    print entities
    print expanded
    print end

    result = []
    i = 0
    for a in sorted(expanded.keys()):
        result.append(text[i:a])

        t = expanded[a]['text']
        b = expanded[a]['b']

        result.append(t)

        i = b

    result.append(text[i:])
    print "".join(result)

    return "".join(result), "".join(end)

def process_status(status):
    global lastweek, nextweek, all_status

    if getattr(status, 'retweeted_status', None) is not None:
        tweet_status = status.retweeted_status
    else:
        tweet_status = status

    author = tweet_status.author
    text = tweet_status.text
    created_at = pytz.utc.localize(tweet_status.created_at)
    created_at = created_at.astimezone(timezone)
    created_at = timezone.normalize(created_at)

    print status.id, created_at, text

    text, end = expand_entities(tweet_status.entities, text)

    print status.id, created_at, text
    print "---------\n\n\n"

    author_url = "https://twitter.com/%s" % (author.screen_name, )
    url = "https://twitter.com/%s/status/%s" % (author.screen_name, status.id_str)

    t = []
    t.append('<div class="tweet">')
    t.append('<img src="%s" alt="" class="avatar" />' %
        escape(author.profile_image_url, True))
    t.append('<div class="tweet_text">')
    t.append('%s @<a href="%s">%s</a><br/>' % (
        escape(author.name), escape(author_url, True), escape(author.screen_name)))
    t.append('%s<br/>' % text)
    t.append('<a href="%s">%s</a>' % (
        escape(url, True), escape(str(created_at))))

    if getattr(status, 'retweeted_status', None) is not None:
        t.append(', retweeted by <a href="%s">%s</a> at %s' % (
            escape(author_url, True),
            escape(status.author.screen_name),
            escape(str(created_at)),
        ))
    t.append(end)
    t.append('</div>')
    t.append('</div>')
    t.append('\n\n')

    year, week, day = created_at.isocalendar()

    if year not in all_status:
        all_status[year] = {}

    if week not in all_status[year]:
        all_status[year][week] = {}

    db["%s_%s_%s_created"%(year, week, status.id)] = tweet_status.created_at.strftime("%Y-%m-%dT%H:%M:%S")
    db["%s_%s_%s_text"%(year, week, status.id)] = "".join(t).encode("utf-8")

# user_timeline

if state.has_option('twitter', 'user_timeline_last_id'):
    user_timeline_last_id = state.getint('twitter', 'user_timeline_last_id')
else:
    user_timeline_last_id = None

print "\nuser_timeline", user_timeline_last_id

last_id = user_timeline_last_id
for status in tweepy.Cursor(api.user_timeline, since_id=last_id, include_entities=True).items():
    process_status(status)
    if user_timeline_last_id is None or user_timeline_last_id < status.id:
        user_timeline_last_id = status.id

print "done:", user_timeline_last_id


# retweeted_by_me

if state.has_option('twitter', 'retweeted_by_me_last_id'):
    retweeted_by_me_last_id = state.getint('twitter', 'retweeted_by_me_last_id')
else:
    retweeted_by_me_last_id = None

print "\nretweeted_by_me", retweeted_by_me_last_id

last_id = retweeted_by_me_last_id
for status in tweepy.Cursor(api.retweeted_by_me, since_id=last_id, include_entities=True).items():
    current_week = process_status(status)
    if retweeted_by_me_last_id is None or retweeted_by_me_last_id < status.id:
        retweeted_by_me_last_id = status.id

print "done:", retweeted_by_me_last_id

print "\nreading cache"
k = db.firstkey()
while k != None:
    year, week, tweet_id, key = k.split("_")
    year = int(year)
    week = int(week)
    tweet_id = int(tweet_id)

    if key != "text":
        k = db.nextkey(k)
        continue

    created = db["%s_%s_%s_created"%(year, week, tweet_id)]
    text = db["%s_%s_%s_text"%(year, week, tweet_id)]

    created = datetime.datetime.strptime(created, "%Y-%m-%dT%H:%M:%S")

#    if year not in all_status:
#        all_status[year] = {}
#
#    if week not in all_status[year]:
#        all_status[year][week] = {}

    if year in all_status:
        if week in all_status[year]:
            print year, week, tweet_id, created
            if created not in all_status[year][week]:
                all_status[year][week][created] = []
            all_status[year][week][created].append(db[k].decode("utf-8"))

    k = db.nextkey(k)

print "\nwriting output file"
for year in all_status:
    for week in all_status[year]:
        lastweek = timezone.localize(tofirstdayinisoweek(year, week))
        nextweek = lastweek + datetime.timedelta(days=7)

        print "processing week from %s to %s" % (lastweek, nextweek)

        if nextweek <= now:
            modified = nextweek
            week_complete = True
        else:
            modified = now
            week_complete = False

        modified = modified.astimezone(pytz.utc)
        modified = pytz.utc.normalize(modified)

        tmpfile = "tempfile.mdwn"
        f = codecs.open(tmpfile, "w", "utf-8")
        title = "Twitter updates %s" % lastweek.date()

        f.write('[[!meta title="%s"]]\n' % title)
        f.write('[[!meta date="%s"]]\n' % modified.strftime("%Y-%m-%dT%H:%M:%S GMT"))
        f.write("# %s\n" % title)
        f.write("\n")

        for created in sorted(all_status[year][week]):
            text_list = all_status[year][week][created]
            for text in text_list:
                f.write(text)

        if week_complete:
            f.write("\n")
            f.write("[[!tag %s]]\n" % "categories/tweets")

        f.close()

        name = "%s/tweets_%s.mdwn" % (lastweek.strftime("%Y"), lastweek.strftime("%Y-%m-%d"))
        name = os.path.join(base, name)

        print "writing file %s" % name
        if os.path.exists(name) and filecmp.cmp(tmpfile, name, shallow=False):
            os.remove(tmpfile)
        else:
            os.rename(tmpfile, name)

state.set('twitter', 'user_timeline_last_id', user_timeline_last_id)
state.set('twitter', 'retweeted_by_me_last_id', retweeted_by_me_last_id)
with open('state.cfg', 'wb') as configfile:
    state.write(configfile)

